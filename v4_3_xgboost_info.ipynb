{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bb97d2-fd10-4272-b503-873f77188066",
   "metadata": {},
   "source": [
    "# XGBoost Model Documentation for Customer Classification\n",
    "\n",
    "## 1. Objective\n",
    "The purpose of this project is to build a machine learning model that classifies customers into two categories based on various behavioral and transactional features. The model helps identify potential customers who are more likely to engage or convert, allowing for more targeted marketing strategies.\n",
    "\n",
    "## 2. Data Overview\n",
    "The dataset includes both raw and engineered features, with a balanced class distribution achieved using SMOTE. The key features used in the final model are:\n",
    "\n",
    "- `vehicle_condition_score`\n",
    "- `trade_in_history`\n",
    "- `engagement_to_age_ratio`\n",
    "- `incentive_received`\n",
    "- `customer_engagement_score`\n",
    "\n",
    "These features were selected using `RandomForestClassifier.feature_importances_` method.\n",
    "\n",
    "## 3. Data Preprocessing\n",
    "- Removed unnecessary columns and duplicates.\n",
    "- Filled missing values using median or most frequent values.\n",
    "- Scaled numerical features using `StandardScaler`.\n",
    "- Applied SMOTE to balance class distribution.\n",
    "- Split the dataset into 80% training and 20% testing.\n",
    "\n",
    "## 4. Feature Engineering\n",
    "Additional features were created to enhance model performance:\n",
    "- `engagement_to_age_ratio` = engagement_score / (age + 1)\n",
    "- `customer_engagement_score` = log1p(engagement_score * incentive_received)\n",
    "\n",
    "## 5. Model Training\n",
    "The final model selected was **XGBoostClassifier**, which outperformed other models in terms of accuracy and F1-score.\n",
    "\n",
    "### Model Parameters\n",
    "- `learning_rate`: 0.1\n",
    "- `max_depth`: 6\n",
    "- `n_estimators`: 100\n",
    "- `random_state`: 42\n",
    "\n",
    "## 6. Evaluation Metrics\n",
    "**Confusion Matrix**:\n",
    "```\n",
    "[[27587  1202]\n",
    " [ 2056  9155]]\n",
    "```\n",
    "\n",
    "**Classification Report**:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.96      0.94     28789\n",
    "           1       0.88      0.82      0.85     11211\n",
    "\n",
    "    accuracy                           0.92     40000\n",
    "   macro avg       0.91      0.89      0.90     40000\n",
    "weighted avg       0.92      0.92      0.92     40000\n",
    "```\n",
    "\n",
    "## 7. Model Comparison\n",
    "XGBoost performed best in terms of:\n",
    "- Overall accuracy: **92%**\n",
    "- Balanced precision and recall across both classes\n",
    "\n",
    "## 8. Recommendations\n",
    "- Use this XGBoost model in production for real-time classification.\n",
    "- Continuously monitor model performance and retrain periodically with fresh data.\n",
    "- Explore additional behavioral features to further improve performance.\n",
    "\n",
    "## 9. Tools and Libraries Used\n",
    "- Python\n",
    "- Pandas, NumPy\n",
    "- Scikit-learn\n",
    "- XGBoost\n",
    "- SMOTE (from imbalanced-learn)\n",
    "\n",
    "## 10. Author\n",
    "This model and documentation were prepared as part of a proof of concept to evaluate machine learning techniques for customer behavior classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8e494-5691-4c20-af52-30fbf16d3c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
